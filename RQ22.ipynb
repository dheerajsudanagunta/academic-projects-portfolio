{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "821a4fb9-d82d-41b4-bcd5-1e3a484071e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw dataset shape: (50694, 29)\n",
      "\n",
      "Columns in the dataset:\n",
      "['year', 'month', 'day', 'statefips', 'freq', 'spend_all', 'spend_aap', 'spend_acf', 'spend_aer', 'spend_apg', 'spend_durables', 'spend_nondurables', 'spend_grf', 'spend_gen', 'spend_hic', 'spend_hcs', 'spend_inperson', 'spend_inpersonmisc', 'spend_remoteservices', 'spend_sgh', 'spend_tws', 'spend_retail_w_grocery', 'spend_retail_no_grocery', 'spend_all_incmiddle', 'spend_all_q1', 'spend_all_q2', 'spend_all_q3', 'spend_all_q4', 'provisional']\n",
      "\n",
      "Data types:\n",
      "year          int64\n",
      "month         int64\n",
      "day           int64\n",
      "statefips     int64\n",
      "freq         object\n",
      "dtype: object\n",
      "\n",
      "Handling missing values...\n",
      "Creating date column...\n",
      "\n",
      "Missing values in key columns:\n",
      "date               0\n",
      "spend_all_q1    4587\n",
      "spend_all_q4    3606\n",
      "dtype: int64\n",
      "\n",
      "Rows after removing missing values: 44145\n",
      "\n",
      "Checking for outliers...\n",
      "Potential outliers in Q1 (Z-score > 3): 178\n",
      "Potential outliers in Q4 (Z-score > 3): 239\n",
      "\n",
      "Full clean dataset size: 44145\n",
      "Recovery dataset size: 28215\n",
      "\n",
      "\n",
      "Starting exploratory data analysis...\n",
      "\n",
      "Descriptive Statistics (Recovery Phase):\n",
      "       Low Income (Q1)  High Income (Q4)  Difference\n",
      "count       28215.0000        28215.0000      0.0000\n",
      "mean            0.1623            0.1170      0.0453\n",
      "std             0.1091            0.1064      0.0027\n",
      "min            -0.3000           -0.5550      0.2550\n",
      "25%             0.0918            0.0509      0.0409\n",
      "50%             0.1640            0.1060      0.0580\n",
      "75%             0.2370            0.1780      0.0590\n",
      "max             0.6490            0.6560     -0.0070\n",
      "\n",
      "Normality Tests (Shapiro-Wilk):\n",
      "Q1 p-value: 0.000000 (Not Normal)\n",
      "Q4 p-value: 0.000000 (Not Normal)\n",
      "\n",
      "\n",
      "Performing statistical tests...\n",
      "\n",
      "Paired t-test results: t = 79.2404, p = 0.0000000000\n",
      "Wilcoxon signed-rank test: W = 82222032.5000, p = 0.0000000000\n",
      "Effect size (Cohen's d): -0.4199\n",
      "The effect size is small\n",
      "Sample size needed for 80% power: 90.0\n",
      "Actual sample size: 28215\n",
      "\n",
      "\n",
      "Performing time series analysis...\n",
      "\n",
      "Correlation between income groups: 0.6041\n",
      "\n",
      "\n",
      "Generating final summary and reporting...\n",
      "\n",
      "Summary Table for RQ2 - Income-Based Spending Differences (Recovery Phase):\n",
      "Sample Size: 28215\n",
      "Q1 Mean: 0.1623\n",
      "Q4 Mean: 0.1170\n",
      "Mean Difference (Q1-Q4): 0.0453\n",
      "T-Statistic: 79.2404\n",
      "P-Value: < 0.001\n",
      "Cohen's d: -0.4199\n",
      "Effect Size: small\n",
      "Correlation: 0.6041\n",
      "Normality (Q1): p = 0.000000 (Not Normal)\n",
      "Normality (Q4): p = 0.000000 (Not Normal)\n",
      "\n",
      "Analysis complete! All results have been saved to CSV files and visualizations to PNG files.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.power import TTestIndPower\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set the aesthetics for plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "# --------- DATA LOADING AND CLEANING ---------\n",
    "# Assuming you're starting with the raw Excel file\n",
    "\n",
    "df = pd.read_excel(\"D:/capstone/datasets/Affinity - State - Daily.xlsx\")\n",
    "print(f\"Raw dataset shape: {df.shape}\")\n",
    "\n",
    "# Check for column names\n",
    "print(\"\\nColumns in the dataset:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Inspect data types\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes.head())\n",
    "\n",
    "# 1. Convert string values of \".\" to NaN, but only for numeric columns\n",
    "print(\"\\nHandling missing values...\")\n",
    "# First, identify the non-numeric columns\n",
    "non_numeric_cols = ['freq']  # Add any other non-numeric columns here\n",
    "\n",
    "# Now handle the conversion only for potential numeric columns\n",
    "for col in df.columns:\n",
    "    if col not in non_numeric_cols and df[col].dtype == object:\n",
    "        df[col] = df[col].replace('.', np.nan).astype(float)\n",
    "\n",
    "# 2. Create date column\n",
    "print(\"Creating date column...\")\n",
    "df['date'] = pd.to_datetime(df[['year', 'month', 'day']])\n",
    "\n",
    "# 3. Check for missing values in key columns\n",
    "missing_values = df[['date', 'spend_all_q1', 'spend_all_q4']].isna().sum()\n",
    "print(\"\\nMissing values in key columns:\")\n",
    "print(missing_values)\n",
    "\n",
    "# 4. Filter out rows with missing values in target columns\n",
    "df_clean = df.dropna(subset=['spend_all_q1', 'spend_all_q4'])\n",
    "print(f\"\\nRows after removing missing values: {len(df_clean)}\")\n",
    "\n",
    "# 5. Check for outliers using Z-score\n",
    "print(\"\\nChecking for outliers...\")\n",
    "z_scores_q1 = np.abs(stats.zscore(df_clean['spend_all_q1'].dropna()))\n",
    "z_scores_q4 = np.abs(stats.zscore(df_clean['spend_all_q4'].dropna()))\n",
    "\n",
    "# Count potential outliers (Z-score > 3)\n",
    "outliers_q1 = np.sum(z_scores_q1 > 3)\n",
    "outliers_q4 = np.sum(z_scores_q4 > 3)\n",
    "\n",
    "print(f\"Potential outliers in Q1 (Z-score > 3): {outliers_q1}\")\n",
    "print(f\"Potential outliers in Q4 (Z-score > 3): {outliers_q4}\")\n",
    "\n",
    "# 6. Create time series dataset\n",
    "df_timeseries = df_clean[['date', 'spend_all_q1', 'spend_all_q4']].copy()\n",
    "df_timeseries = df_timeseries.sort_values('date')\n",
    "\n",
    "# 7. Filter to recovery period\n",
    "df_recovery = df_timeseries[df_timeseries['date'] >= '2021-01-01']\n",
    "print(f\"\\nFull clean dataset size: {len(df_timeseries)}\")\n",
    "print(f\"Recovery dataset size: {len(df_recovery)}\")\n",
    "\n",
    "# Save cleaned datasets\n",
    "df_timeseries.to_csv('clean_timeseries_data.csv', index=False)\n",
    "df_recovery.to_csv('clean_recovery_data.csv', index=False)\n",
    "\n",
    "# --------- EXPLORATORY DATA ANALYSIS ---------\n",
    "print(\"\\n\\nStarting exploratory data analysis...\")\n",
    "\n",
    "# 1. Descriptive statistics\n",
    "recovery_stats_q1 = df_recovery['spend_all_q1'].describe()\n",
    "recovery_stats_q4 = df_recovery['spend_all_q4'].describe()\n",
    "\n",
    "# Create a comparison DataFrame\n",
    "stats_comparison = pd.DataFrame({\n",
    "    'Low Income (Q1)': recovery_stats_q1,\n",
    "    'High Income (Q4)': recovery_stats_q4,\n",
    "    'Difference': recovery_stats_q1 - recovery_stats_q4\n",
    "})\n",
    "print(\"\\nDescriptive Statistics (Recovery Phase):\")\n",
    "print(stats_comparison.round(4))\n",
    "\n",
    "# 2. Visualization of distributions\n",
    "plt.figure(figsize=(14, 6))\n",
    "# Histogram of spending by income group\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df_recovery['spend_all_q1'], alpha=0.5, label='Low Income (Q1)', kde=True)\n",
    "sns.histplot(df_recovery['spend_all_q4'], alpha=0.5, label='High Income (Q4)', kde=True)\n",
    "plt.title('Distribution of Spending by Income Group (Recovery Phase)')\n",
    "plt.xlabel('Spending Index')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "# QQ plot to check distribution of differences\n",
    "plt.subplot(1, 2, 2)\n",
    "diff = df_recovery['spend_all_q4'] - df_recovery['spend_all_q1']\n",
    "sm.qqplot(diff, line='s', ax=plt.gca())\n",
    "plt.title('QQ Plot of High-Low Income Spending Differences')\n",
    "plt.tight_layout()\n",
    "plt.savefig('recovery_distributions.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Box plots\n",
    "plt.figure(figsize=(10, 6))\n",
    "boxplot_data = pd.melt(df_recovery[['spend_all_q1', 'spend_all_q4']],\n",
    "                       var_name='Income Group', value_name='Spending Index')\n",
    "boxplot_data['Income Group'] = boxplot_data['Income Group'].map({\n",
    "    'spend_all_q1': 'Low Income (Q1)',\n",
    "    'spend_all_q4': 'High Income (Q4)'\n",
    "})\n",
    "sns.boxplot(x='Income Group', y='Spending Index', data=boxplot_data)\n",
    "plt.title('Box Plot of Spending by Income Group (Recovery Phase)')\n",
    "plt.grid(True, axis='y')\n",
    "plt.savefig('recovery_boxplot.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 3. Distribution normality test\n",
    "print(\"\\nNormality Tests (Shapiro-Wilk):\")\n",
    "_, p_q1 = stats.shapiro(df_recovery['spend_all_q1'])\n",
    "_, p_q4 = stats.shapiro(df_recovery['spend_all_q4'])\n",
    "print(f\"Q1 p-value: {p_q1:.6f} ({'Normal' if p_q1 > 0.05 else 'Not Normal'})\")\n",
    "print(f\"Q4 p-value: {p_q4:.6f} ({'Normal' if p_q4 > 0.05 else 'Not Normal'})\")\n",
    "\n",
    "# --------- STATISTICAL TESTING ---------\n",
    "print(\"\\n\\nPerforming statistical tests...\")\n",
    "\n",
    "# 1. Paired t-test\n",
    "t_stat, p_value = stats.ttest_rel(df_recovery['spend_all_q1'], df_recovery['spend_all_q4'])\n",
    "print(f\"\\nPaired t-test results: t = {t_stat:.4f}, p = {p_value:.10f}\")\n",
    "\n",
    "# 2. Wilcoxon signed-rank test (non-parametric alternative)\n",
    "w_stat, w_p_value = stats.wilcoxon(df_recovery['spend_all_q1'], df_recovery['spend_all_q4'])\n",
    "print(f\"Wilcoxon signed-rank test: W = {w_stat:.4f}, p = {w_p_value:.10f}\")\n",
    "\n",
    "# 3. Calculate effect size (Cohen's d)\n",
    "cohens_d = (df_recovery['spend_all_q4'].mean() - df_recovery['spend_all_q1'].mean()) / \\\n",
    "           np.sqrt((df_recovery['spend_all_q1'].std()**2 + df_recovery['spend_all_q4'].std()**2) / 2)\n",
    "print(f\"Effect size (Cohen's d): {cohens_d:.4f}\")\n",
    "\n",
    "# Interpret Cohen's d\n",
    "if abs(cohens_d) < 0.2:\n",
    "    effect_interpretation = \"negligible\"\n",
    "elif abs(cohens_d) < 0.5:\n",
    "    effect_interpretation = \"small\"\n",
    "elif abs(cohens_d) < 0.8:\n",
    "    effect_interpretation = \"medium\"\n",
    "else:\n",
    "    effect_interpretation = \"large\"\n",
    "print(f\"The effect size is {effect_interpretation}\")\n",
    "\n",
    "# 4. Calculate statistical power\n",
    "power_analysis = TTestIndPower()\n",
    "sample_size_needed = power_analysis.solve_power(\n",
    "    effect_size=abs(cohens_d),\n",
    "    power=0.8,\n",
    "    alpha=0.05\n",
    ")\n",
    "print(f\"Sample size needed for 80% power: {sample_size_needed:.1f}\")\n",
    "print(f\"Actual sample size: {len(df_recovery)}\")\n",
    "\n",
    "# --------- TIME SERIES ANALYSIS ---------\n",
    "print(\"\\n\\nPerforming time series analysis...\")\n",
    "\n",
    "# 1. Group by month and calculate monthly averages\n",
    "monthly_data = df_recovery.groupby(pd.Grouper(key='date', freq='M')).agg({\n",
    "    'spend_all_q1': 'mean',\n",
    "    'spend_all_q4': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Calculate differences\n",
    "monthly_data['difference'] = monthly_data['spend_all_q1'] - monthly_data['spend_all_q4']\n",
    "\n",
    "# 2. Plot time series\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(monthly_data['date'], monthly_data['spend_all_q1'], label='Low Income (Q1)', \n",
    "         marker='o', linewidth=2)\n",
    "plt.plot(monthly_data['date'], monthly_data['spend_all_q4'], label='High Income (Q4)', \n",
    "         marker='s', linewidth=2)\n",
    "plt.title('Monthly Average Spending by Income Group (Recovery Phase)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Spending Index')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "bars = plt.bar(monthly_data['date'], monthly_data['difference'])\n",
    "# Color the bars based on whether q1 is higher (blue) or lower (red) than q4\n",
    "for i, diff in enumerate(monthly_data['difference']):\n",
    "    bars[i].set_color('blue' if diff > 0 else 'red')\n",
    "plt.title('Monthly Difference (Low - High Income Spending)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Difference')\n",
    "plt.axhline(y=0, color='black', linestyle='-')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig('recovery_time_series.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 3. Moving average to show trend\n",
    "monthly_data['rolling_diff'] = monthly_data['difference'].rolling(window=3).mean()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(monthly_data['date'], monthly_data['difference'], label='Monthly Difference', marker='o')\n",
    "plt.plot(monthly_data['date'], monthly_data['rolling_diff'], label='3-Month Moving Average', \n",
    "         linewidth=3, color='red')\n",
    "plt.title('Trend in Low-High Income Spending Gap (Recovery Phase)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Spending Gap (Q1 - Q4)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('recovery_trend.png', dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# 4. Calculate correlation between income groups\n",
    "correlation = df_recovery['spend_all_q1'].corr(df_recovery['spend_all_q4'])\n",
    "print(f\"\\nCorrelation between income groups: {correlation:.4f}\")\n",
    "\n",
    "# --------- SUMMARY STATISTICS AND REPORTING ---------\n",
    "print(\"\\n\\nGenerating final summary and reporting...\")\n",
    "\n",
    "# 1. Create summary table for reporting\n",
    "summary_table = pd.DataFrame({\n",
    "    'Metric': ['Sample Size', 'Q1 Mean', 'Q4 Mean', 'Mean Difference (Q1-Q4)', \n",
    "               'T-Statistic', 'P-Value', \"Cohen's d\", 'Effect Size', \n",
    "               'Correlation', 'Normality (Q1)', 'Normality (Q4)'],\n",
    "    'Value': [len(df_recovery), \n",
    "             f\"{df_recovery['spend_all_q1'].mean():.4f}\", \n",
    "             f\"{df_recovery['spend_all_q4'].mean():.4f}\",\n",
    "             f\"{df_recovery['spend_all_q1'].mean() - df_recovery['spend_all_q4'].mean():.4f}\",\n",
    "             f\"{t_stat:.4f}\",\n",
    "             f\"< 0.001\" if p_value < 0.001 else f\"{p_value:.4f}\",\n",
    "             f\"{cohens_d:.4f}\",\n",
    "             effect_interpretation,\n",
    "             f\"{correlation:.4f}\",\n",
    "             f\"p = {p_q1:.6f} ({'Normal' if p_q1 > 0.05 else 'Not Normal'})\",\n",
    "             f\"p = {p_q4:.6f} ({'Normal' if p_q4 > 0.05 else 'Not Normal'})\"]\n",
    "})\n",
    "\n",
    "# 2. Save summary table\n",
    "summary_table.to_csv('recovery_analysis_summary.csv', index=False)\n",
    "\n",
    "# 3. Print final summary\n",
    "print(\"\\nSummary Table for RQ2 - Income-Based Spending Differences (Recovery Phase):\")\n",
    "for i, row in summary_table.iterrows():\n",
    "    print(f\"{row['Metric']}: {row['Value']}\")\n",
    "\n",
    "print(\"\\nAnalysis complete! All results have been saved to CSV files and visualizations to PNG files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d71fe8-c60d-44a7-bd23-159c08d5b7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
